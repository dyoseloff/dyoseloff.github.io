<!DOCTYPE html>
<html lang="en">

  
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <title>Best Model for the Data | 
  Danielle Yoseloff
</title>
  

  
  <meta name="description" content="Multiple regression model assesment and reassessment in R">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/r/outliers/collinearity/residuals/interaction/2017/02/12/name.html">
  <link rel="alternate" type="application/rss+xml" title="
  Danielle Yoseloff
" href="/feed.xml">

  
  
  <meta name="theme-color" content="#ffffff">

  

  

  

  

  
</head>



  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <div class="site-header-float">
    



<a class="site-title with-pitch" href="




/
">
  
    
  Danielle Yoseloff

  
</a>

    
      <span class="site-pitch">
  Data Scientist
</span>
    

    
    </div>

    
    

  </div>

</header>


    
    <main class="post-content" aria-label="Content">
    
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  
  <header class="post-header">
  
    
    <div class="wrapper">
      <h1 class="post-title" itemprop="name headline">Best Model for the Data</h1>
      <p class="post-meta">
        <time datetime="2017-02-12T20:44:03-05:00" itemprop="datePublished">
          

  Feb 12, 2017


        </time>
        




         • 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Danielle Yoseloff</span></span>
        
      </p>
      <h3 class="post-summary">Multiple regression model assesment and reassessment in R</h3>
    </div>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>It can be complicated to asses the best way to model data. How can you know if your model is good? how can you know what steps to take to make it better? Did you really make it better? In our exploration of these questions we will come across concepts such at interaction variables, residual plots, outliers, and collinearity.</p>

<p>I’m working with a csv file which read into my R ddocument and named ‘data2’. It contains 100 observations with the variables y, age, sexf, x1, x2, and x3. Our goal is to come up with a model that is very good at predicting y.</p>

<p>First let’s look at how good the go-to regression is. That is, y regressed on all the independent variables.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">two</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sexf</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="n">x</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">two</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/s1.png" alt="first summ" />
The Rsquared is .081 which is quite low indicating the model is not a good predictor of y. Let’s also note, we observe age and x1 to be the significant variables.</p>

<p>Step 1: confirm linearity. One of the fundumental assumptions of a linear model is the assumption that all variables are linear. Let’s check put looking at plots of all independent variables graphed against the residuals.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">resid</span><span class="p">(</span><span class="n">two</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">residuals</span><span class="o">~</span><span class="n">age</span><span class="p">,</span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">residuals</span><span class="o">~</span><span class="n">sexf</span><span class="p">,</span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">residuals</span><span class="o">~</span><span class="n">x</span><span class="m">1</span><span class="p">,</span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">residuals</span><span class="o">~</span><span class="n">x</span><span class="m">2</span><span class="p">,</span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">residuals</span><span class="o">~</span><span class="n">x</span><span class="m">3</span><span class="p">,</span><span class="n">data2</span><span class="p">)</span></code></pre></figure>

<p>For the regression plots to be linear we want to see a random scatter of the observations. 
<img src="/assets/res1.png" alt="residual plots" />
<img src="/assets/res2.png" alt="residual plots" />
<img src="/assets/res3.png" alt="residual plots" />
The plots for age, x1, and x3 look random, so we can assume they are linear. The residual plot for x2 looks a bit different but is also random when we think about it. The variable for sex is either 0 or 1, so given that the obervations can only be at those two marks on the axis we are really looking for a random spread on the y axis. And yes, there doesn’t appear to be a cluster of the data at any point of the y axis. Now finally we have the resudual plot for x2. It appears to be following the trend of a negative proabola. This is a red flag that the x2 variable is nonlinear.</p>

<p>One way to compensate for this linearity problem is by adding another variable to the model that is the square of the nonlinear vairable. To do this I created a new column in our data set that is x2squared, then added that term in our regression. Additionally I run a summary of our model so we can asses it.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">data2</span><span class="o">$</span><span class="n">x</span><span class="m">22</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data2</span><span class="o">$</span><span class="n">x</span><span class="m">2</span><span class="o">^</span><span class="m">2</span><span class="w">
</span><span class="n">three</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sexf</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="n">x</span><span class="m">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">22</span><span class="p">,</span><span class="w"> </span><span class="n">data2</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">three</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/s2.png" alt="second summary" />
Our Rsquared value jumps to 0.787. This model is a much better fit than our previous model without the x2squared variable. Now we see that x2 and x2squared are the significat variabels.</p>

<p>Step 2: outliers. We can improve a model by checking for outliers and removing any we find significant. Let’s look at two criteria for determining outliers. 
The first is studentized residuals which follow a t table with n-k-1 degrees of freedom (n=sample size, k= number of regressor in model). In our case n=100 and k=6. our output will give us studentized residual values for each observation but these can be hard to read so, let’s also graph it.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">studentr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rstudent</span><span class="p">(</span><span class="n">three</span><span class="p">)</span><span class="w">
</span><span class="n">student</span><span class="w"> </span><span class="n">r</span><span class="w"> 
</span><span class="n">plot</span><span class="p">(</span><span class="n">studentr</span><span class="p">)</span><span class="w">
</span><span class="n">points</span><span class="p">(</span><span class="m">7</span><span class="p">,</span><span class="n">studentr</span><span class="p">[</span><span class="m">7</span><span class="p">],</span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span></code></pre></figure>

<p>It’s easy to see one point which is significant. I found the outlier point to be observation 7 because I could see it was around 10, then played around with coloring different observations on the graph until the outlier light up red. This was an easy way to get around searching through the list of numbers in the R output
<img src="/assets/srval.png" alt="sr values" />
<img src="/assets/studp.png" alt="sr plot" /></p>

<p>The second way to identify outliers is by calculating the Cooks Distance for each observation. Influencial point for cooks distance will have a vale greater than 4/n. In our case, we’re looking for values greater than 4/100 or .04.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cooks.distance</span><span class="p">(</span><span class="n">three</span><span class="p">)</span><span class="w">
</span><span class="n">cook</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cooks.distance</span><span class="p">(</span><span class="n">three</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">cook</span><span class="p">)</span><span class="w">
</span><span class="n">points</span><span class="p">(</span><span class="m">7</span><span class="p">,</span><span class="n">cook</span><span class="p">[</span><span class="m">7</span><span class="p">],</span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span></code></pre></figure>

<p>Similar to the studentized residuals we see observation 7 is an outlier. 
<img src="/assets/cdval.png" alt="cd values" />
<img src="/assets/cookp.png" alt="cd plot " /></p>

<p>After confirming obervation 7 is an outlier the next step is to remove it. To do this we will be creating a new dataframe called ‘newdata’ which is a subset of our data. It will have all 8 of our variables but only 99 obervations.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">newdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data2</span><span class="p">[</span><span class="o">-</span><span class="nf">c</span><span class="p">(</span><span class="m">7</span><span class="p">),]</span></code></pre></figure>

<p>Let’s see if removing the outlier imporved our model</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sexf</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="n">x</span><span class="m">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">22</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/s3.png" alt="summary 3" />
Yes, removing the outlier increase the Rsquared of the model to .9871 which is very high. We still see that only variables x2 and x2 squared are significant.</p>

<p>Step 3: collinearity. Variance inflation factor(VIF) is a value assigned to each indepented variable in a model to describe collinearity. A high VIF value means that variable is highly correlated with another variable in the model. We should expect that x2 and x2squared will have high VIF values because the are highly correlated. But, let’s check if any other variables in our model are correlated.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">vif</span><span class="p">(</span><span class="n">m</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/vif.png" alt="vif" />
It appears age and x1 are also highly correlated. When two variable that are highly correlated are in the model it can create problems. Because both are present neither would seem like an important contribution. However, when one is not present the other may be highly significant. So, let’s remove x1 from our model and th updated model.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="m">5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sexf</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="n">x</span><span class="m">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="m">22</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">m</span><span class="m">5</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/s4.png" alt="summary4" />
Our rsquared value has stayed just as strong as before at .9871 so our model is good at predicting the data. The difference is now, x2 x2squared, and age are significant predictors. At this point we can be very satified with the model we have chosen to predict our data.</p>

  </div>

  
  <div class="post-author">
    
      <a href="
  
">
        <img class="user-picture" src="https://github.com/dyoseloff.png" alt="Danielle Yoseloff">
      </a>
    
      <ul class="user-info">
        <li class="user-name">
          Danielle Yoseloff
        </li>
        <li class="user-shortbio">
  I'm a data scientist with a BA in Mathamatics and Statistics
</li>
      </ul>
  </div>
  

</article>

      </div>
    </main>

    

<footer class="site-footer">

  <div class="wrapper">

      <ul class="footer-col footer-col-1">
        <li>
          



<a class="" href="




/
">
  
    
  Danielle Yoseloff

  
</a>


        

      </ul>

      
        <nav>
        

<span class="nav-list-title">Menu:</span>
<ul class="nav-list footer-col footer-col-2">






  
  <li><a class="page-link" href="/about/">About</a></li>
  



  



  



  



  


</ul>

        
<span class="contact-list-title">
  Links :
</span>
<ul class="contact-list single-col">
  <li>
    
<a href="/feed.xml" title="RSS"><span class="icon icon--feed"><svg fill="#000000" height="16" viewBox="0 0 24 24" width="16" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
</span>
  <span class="username">
    RSS feed
  </span>
</a>


  </li>

  
  <li>
    <a target="_blank" href="https://github.com/dyoseloff" title="Github"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">dyoseloff</span></a>

  </li>
  

  

  

  

</ul>

        </nav>
      

    <div class="bottom">

      
      

      <div class="tech">
        <a target="_blank" href="https://jekyllrb.com/">Jekyll</a> + <a target="_blank" href="https://github.com/gaalcaras/academic">Academic</a>
        
        + <a target="_blank" href="https://github.com/dyoseloff/dyoseloff.github.io">Source</a>
        
      </div>

      <div class="legal">
      ©
      



<a class="" href="




/
">
  
    
  Danielle Yoseloff

  
</a>

      
      
      
      (2017)
      
      
     </div>
    </div>

  </div>
</footer>


<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  </body>

</html>
